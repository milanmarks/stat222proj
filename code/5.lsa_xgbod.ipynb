{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-12T22:30:58.159029Z",
     "start_time": "2024-04-12T22:30:57.403306Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import average_precision_score, classification_report\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "\n",
    "from scipy import sparse\n",
    "\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from time import time\n",
    "\n",
    "from imblearn.ensemble import EasyEnsembleClassifier\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.pipeline import Pipeline\n",
    "\n",
    "from pyod.utils.data import evaluate_print\n",
    "from pyod.models.xgbod import XGBOD \n",
    "\n",
    "from joblib import dump, load\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = set(stopwords.words('english'))\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "st = SnowballStemmer('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bc2ff86a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def benchmark(clf, X_train, y_train, X_test, y_test):\n",
    "    print(\"_\" * 80)\n",
    "    print(\"Training: \")\n",
    "    print(clf)\n",
    "    t0 = time()\n",
    "    clf.fit(X_train, y_train)\n",
    "    train_time = time() - t0\n",
    "    print(f\"train time: {train_time:.3}s\")\n",
    "\n",
    "    t0 = time()\n",
    "    pred = clf.predict(X_test)\n",
    "    test_time = time() - t0\n",
    "    print(f\"test time:  {test_time:.3}s\")\n",
    "\n",
    "    score = average_precision_score(y_test, pred)\n",
    "    print(f\"PR AUC:   {score:.3}\")\n",
    "\n",
    "    print(classification_report(y_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "157a3475",
   "metadata": {},
   "outputs": [],
   "source": [
    "def running_baseline_models(X_train, y_train, X_test, y_test):\n",
    "    # Logistic regression \n",
    "    lr = LogisticRegression(max_iter = 1000, fit_intercept = False, class_weight='balanced')\n",
    "    lr.fit(X_train, y_train)\n",
    "    benchmark(lr, X_train, y_train, X_test, y_test)\n",
    "\n",
    "    # SVM \n",
    "    param_grid = {\n",
    "        'C': [10, 100, 1000],\n",
    "        'gamma': ['scale', 'auto'],\n",
    "        'kernel': ['rbf'] \n",
    "    }\n",
    "\n",
    "    svm = GridSearchCV(SVC(class_weight = 'balanced', random_state = 42, probability=True), param_grid, scoring = 'average_precision', cv = 5)\n",
    "    svm.fit(X_train, y_train)\n",
    "\n",
    "    # \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba29c27d",
   "metadata": {},
   "source": [
    "# Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "29ff60905c325467",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-12T22:42:06.019867Z",
     "start_time": "2024-04-12T22:41:51.258761Z"
    }
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('../data/train_test_set.csv')\n",
    "data = pd.get_dummies(data, columns = ['main_industry', 'year'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a5f4bf43",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = data[data['train'] == 1].drop(columns=['cik', 'sic', 'sic_description', 'filedate', 'accession_num',\n",
    "       'primary_doc', 'filelink', 'bank_status', 'train'])\n",
    "X_test = data[data['train'] == 0].drop(columns=['cik', 'sic', 'sic_description', 'filedate', 'accession_num',\n",
    "       'primary_doc', 'filelink', 'bank_status', 'train'])\n",
    "y_train = data[data['train']==1]['bank_status']\n",
    "y_test = data[data['train']==0]['bank_status']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a010c0a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardization for numerical features \n",
    "scaler = StandardScaler().fit(X_train.iloc[:, 0:23])\n",
    "scaled_terms_train = pd.DataFrame(scaler.transform(X_train.iloc[:, 0:23]), columns = X_train.columns[0:23])\n",
    "X_train_scaled = pd.concat([scaled_terms_train, X_train.iloc[:,23:].reset_index(drop = True)], axis = 1)\n",
    "scaled_terms_test = pd.DataFrame(scaler.transform(X_test.iloc[:, 0:23]), columns = X_test.columns[0:23])\n",
    "X_test_scaled = pd.concat([scaled_terms_test, X_test.iloc[:,23:].reset_index(drop = True)], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0938ef19",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_text_train = X_train['clean_items']\n",
    "X_text_test = X_test['clean_items']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "52a8046658b6c3d2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-11T01:36:02.787258Z",
     "start_time": "2024-04-11T01:36:02.773704Z"
    }
   },
   "outputs": [],
   "source": [
    "# tf-idf features for text features \n",
    "vectorizer = TfidfVectorizer(\n",
    "    sublinear_tf=True, max_df=0.5, min_df=5, stop_words=\"english\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "28de8f743efbcc2f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-11T01:39:26.210263Z",
     "start_time": "2024-04-11T01:38:36.792934Z"
    }
   },
   "outputs": [],
   "source": [
    "X_text_train = vectorizer.fit_transform(X_text_train)\n",
    "X_text_test = vectorizer.transform(X_text_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3897f46d",
   "metadata": {},
   "outputs": [],
   "source": [
    "svd = TruncatedSVD(n_components=200)\n",
    "X_pca_train = svd.fit_transform(X_text_train)\n",
    "X_pca_test = svd.transform(X_text_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a2381195",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/haodong/opt/anaconda3/lib/python3.9/site-packages/pyod/models/base.py:430: UserWarning: y should not be presented in unsupervised learning.\n",
      "  warnings.warn(\n",
      "/Users/haodong/opt/anaconda3/lib/python3.9/site-packages/xgboost/core.py:160: UserWarning: [17:37:04] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:742: \n",
      "Parameters: { \"silent\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "On Training Data:\n",
      "XGBOD ROC:1.0, precision @ rank n:0.9744\n",
      "\n",
      "On Test Data:\n",
      "XGBOD ROC:0.9841, precision @ rank n:0.5385\n"
     ]
    }
   ],
   "source": [
    "clf_name = 'XGBOD'\n",
    "clf = XGBOD(random_state=42)\n",
    "clf.fit(X_pca_train, y_train)\n",
    "\n",
    "# get the prediction labels and outlier scores of the training data\n",
    "y_train_pred = clf.labels_  # binary labels (0: inliers, 1: outliers)\n",
    "y_train_scores = clf.decision_scores_  # raw outlier scores\n",
    "\n",
    "# get the prediction on the test data\n",
    "y_test_pred = clf.predict(X_pca_test)  # outlier labels (0 or 1)\n",
    "y_test_scores = clf.decision_function(X_pca_test)  # outlier scores\n",
    "\n",
    "# evaluate and print the results\n",
    "print(\"\\nOn Training Data:\")\n",
    "evaluate_print(clf_name, y_train, y_train_scores)\n",
    "print(\"\\nOn Test Data:\")\n",
    "evaluate_print(clf_name, y_test, y_test_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9677b93b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../res/xgbod.joblib']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dump(clf, '../res/xgbod.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "98979181",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5497131396543435"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "average_precision_score(y_test, y_test_scores)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
